{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Preschool school details are retrieved from \"preschool_loc_details_raw.csv\".\n",
    "2. MOE school details (including primary, secondary, mixed level schools, and centralised institutes like Millennia Institute) are obtained from \"moe_schools_raw.csv\".\n",
    "3. Tertiary school names (such as polytechnics, ITEs, and universities) are extracted from Wikipedia pages.\n",
    "\n",
    "For preschools and MOE schools, location details (e.g., address, latitude, longitude) are retrieved using the postal code provided in the CSV files via the OneMap API.\n",
    "\n",
    "For tertiary institutions, location details are obtained using Google Places Text Search instead of the OneMap API. This decision was based on a sample comparison, where Google Places Text Search provided more accurate results, particularly for institutions with multiple campuses, such as Singapore Institute of Technology, which has locations across Singapore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- OneMap API Set-Up\n",
    "ONEMAP_BASE_URL = \"https://www.onemap.gov.sg/api/common/elastic/search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- Google API Set-Up\n",
    "GOOGLE_API_KEY = \"AIzaSyDpu7X3vaLLr2GhCX6BcNWhfUtcJwU8F-A\"\n",
    "TEXT_SEARCH_URL = \"https://maps.googleapis.com/maps/api/place/textsearch/json\"\n",
    "GEOCODE_URL = \"https://maps.googleapis.com/maps/api/geocode/json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get latitude and longitude using OneMap API for postal code\n",
    "def get_lat_lon_onemap(postal_code):\n",
    "\n",
    "    # Parameters for the API call (including your API Key)\n",
    "    params = {\n",
    "        'searchVal': postal_code,\n",
    "        'returnGeom': 'Y',\n",
    "        'getAddrDetails': 'Y'\n",
    "    }\n",
    "    \n",
    "    # Make the API request\n",
    "    response = requests.get(ONEMAP_BASE_URL, params=params)\n",
    "    \n",
    "    # Parse the response JSON\n",
    "    data = response.json()\n",
    "    \n",
    "    # Check if the response contains results\n",
    "    if data['found'] > 0:\n",
    "        # Extract latitude and longitude from the response\n",
    "        latitude = data['results'][0]['LATITUDE']\n",
    "        longitude = data['results'][0]['LONGITUDE']\n",
    "        return latitude, longitude\n",
    "    else:\n",
    "        # Return None if no results are found\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-School Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preschool_raw = pd.read_csv('preschool_loc_details_raw.csv', na_values=['na', 'NA', 'N/A', 'NULL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where 'centre_name' is null\n",
    "df_preschool_raw = df_preschool_raw[df_preschool_raw['centre_name'].notnull()]\n",
    "\n",
    "# Remove duplicates based on both 'centre_name' and 'postal_code'\n",
    "df_preschool_raw = df_preschool_raw.drop_duplicates(subset=['centre_name', 'postal_code'], keep='first')\n",
    "\n",
    "# Obtain relevant columns\n",
    "df_preschool_loc = df_preschool_raw[['centre_name', 'centre_address', 'postal_code']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to get lat and lon for each preschool based on postal code\n",
    "df_preschool_loc[['latitude', 'longitude']] = df_preschool_loc['postal_code'].apply(get_lat_lon_onemap).apply(pd.Series)\n",
    "\n",
    "df_preschool_loc.loc[:, 'category'] = 'Preschool'\n",
    "df_preschool_loc.rename(columns={'centre_name': 'school_name'}, inplace=True)\n",
    "df_preschool_loc.drop(columns={'postal_code'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOE Schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_moe_raw = pd.read_csv('moe_schools_raw.csv', na_values=['na', 'NA', 'N/A', 'NULL'])\n",
    "df_moe_raw = df_moe_raw.drop_duplicates(subset=['school_name', 'postal_code'], keep='first')\n",
    "df_moe_loc = df_moe_raw[['school_name', 'address', 'postal_code', 'mainlevel_code']].copy()\n",
    "\n",
    "df_moe_loc[['latitude', 'longitude']] = df_moe_loc['postal_code'].apply(get_lat_lon_onemap).apply(pd.Series)\n",
    "df_moe_loc.rename(columns={'mainlevel_code': 'category'}, inplace=True)\n",
    "df_moe_loc.drop(columns=['postal_code'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tertiary Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- Wiki URLs\n",
    "# School names are obtained from multiple source that give the most complete list of each category.\n",
    "UNI_WIKI_URL = \"https://en.wikipedia.org/wiki/List_of_universities_in_Singapore\"\n",
    "POLY_WIKI_URL = \"https://en.wikipedia.org/wiki/Education_in_Singapore\"\n",
    "ITE_WIKI_URL = \"https://en.wikipedia.org/wiki/Institute_of_Technical_Education#Colleges\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain school names, category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_university_names():\n",
    "    # Fetch the page content\n",
    "    response = requests.get(UNI_WIKI_URL)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Find the \"Universities in Singapore\" section by its ID\n",
    "    section_div = soup.find(\"div\", id=\"Universities_in_Singapore145\")\n",
    "\n",
    "    # List to store university data\n",
    "    university_list = []\n",
    "\n",
    "    if section_div:\n",
    "        # Locate \"Education in Singapore\" section to stop before it\n",
    "        stop_section = soup.find(\"div\", id=\"Education_in_Singapore254\")\n",
    "\n",
    "        # Find all categories (th elements)\n",
    "        categories = section_div.find_all_next(\"th\", scope=\"row\", class_=\"navbox-group\")\n",
    "\n",
    "        for category in categories:\n",
    "            # Stop if we reach \"Education in Singapore\"\n",
    "            if stop_section and category.find_previous(\"div\") == stop_section:\n",
    "                break\n",
    "\n",
    "            # Find the corresponding <td> which contains university names\n",
    "            next_td = category.find_next_sibling(\"td\")\n",
    "            if next_td:\n",
    "                for link in next_td.find_all(\"a\"):\n",
    "                    university_name = link.get_text(strip=True)\n",
    "                    university_list.append({\"school_name\": university_name, \"category\": \"University\"})\n",
    "    return pd.DataFrame(university_list)\n",
    "\n",
    "df_universities = get_university_names()\n",
    "df_universities = df_universities[df_universities['school_name'] != 'Singapore College of Islamic Studies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polytechnics():\n",
    "    response = requests.get(POLY_WIKI_URL)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Find the \"Polytechnics\" section\n",
    "    polytechnic_section = soup.find(\"h2\", {\"id\": \"Polytechnics\"})\n",
    "    polytechnic_list = []\n",
    "\n",
    "    if polytechnic_section:\n",
    "        # Locate the nearest paragraph (<p>) containing polytechnic names\n",
    "        para = polytechnic_section.find_next(\"p\")\n",
    "\n",
    "        # Extract all links within that paragraph\n",
    "        for link in para.find_all(\"a\"):\n",
    "            polytechnic_name = link.get_text(strip=True)\n",
    "            polytechnic_list.append({\"school_name\": polytechnic_name, \"category\": \"Polytechnic\"})\n",
    "    \n",
    "    return pd.DataFrame(polytechnic_list)\n",
    "\n",
    "df_polytechnics = get_polytechnics()\n",
    "df_polytechnics = df_polytechnics[df_polytechnics['school_name'] != '[71]'] # data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ite_names():\n",
    "    response = requests.get(ITE_WIKI_URL)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Find the \"Colleges\" section under an <h2> tag\n",
    "    ite_colleges_header = soup.find(\"h2\", {\"id\": \"Colleges\"})\n",
    "    ite_colleges_list = []\n",
    "\n",
    "    if ite_colleges_header:\n",
    "        # Locate the first <ul> after the <h2> heading (which contains the list)\n",
    "        ul = ite_colleges_header.find_next(\"ul\")\n",
    "\n",
    "        if ul:\n",
    "            for link in ul.find_all(\"a\"):\n",
    "                college_name = link.get_text(strip=True)\n",
    "                ite_colleges_list.append({\"school_name\": college_name, \"category\": \"ITE College\"})\n",
    "\n",
    "    return pd.DataFrame(ite_colleges_list)\n",
    "\n",
    "df_ite_colleges = get_ite_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tertiary = pd.concat([df_universities, df_polytechnics, df_ite_colleges], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain location information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ter_school_details_google(school_name):\n",
    "    query = school_name + \" Singapore\"  # Construct query for text search\n",
    "    \n",
    "    params = {\n",
    "        \"query\": query,  # The text search query\n",
    "        \"key\": GOOGLE_API_KEY\n",
    "    }\n",
    "    \n",
    "    response = requests.get(TEXT_SEARCH_URL, params=params)\n",
    "    data = response.json()\n",
    "    \n",
    "    results_list = []\n",
    "    \n",
    "    if data[\"status\"] == \"OK\":\n",
    "        for result in data[\"results\"]:  # Loop through all the results\n",
    "            name = result[\"name\"]\n",
    "            address = result[\"formatted_address\"]\n",
    "            lat = result[\"geometry\"][\"location\"][\"lat\"]\n",
    "            lng = result[\"geometry\"][\"location\"][\"lng\"]\n",
    "            \n",
    "            results_list.append({\n",
    "                \"school_name\": school_name,\n",
    "                \"google_school_name\": name,  # Store the official name returned\n",
    "                \"address\": address,\n",
    "                \"longitude\": lng,\n",
    "                \"latitude\": lat\n",
    "            })\n",
    "    \n",
    "    # If no valid results, return a placeholder\n",
    "    if not results_list:\n",
    "        results_list.append({\n",
    "            \"school_name\": school_name,\n",
    "            \"google_school_name\": None,\n",
    "            \"address\": None,\n",
    "            \"longitude\": None,\n",
    "            \"latitude\": None\n",
    "        })\n",
    "    \n",
    "    return results_list  # Returns a list of all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ter_loc_details = []\n",
    "for _, row in df_tertiary.iterrows():\n",
    "    school_name = row['school_name']\n",
    "    category = row['category']\n",
    "    ter_loc_details.extend(get_ter_school_details_google(school_name))  # Extend with multiple results\n",
    "\n",
    "df_ter_loc_details = pd.DataFrame(ter_loc_details)\n",
    "\n",
    "# Merge back \n",
    "df_tertiary = df_tertiary.merge(df_ter_loc_details, on=['school_name'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual cleaning\n",
    "df_tertiary = df_tertiary[df_tertiary['google_school_name'] != 'Singapore Institute of Manufacturing Technology (SIMTech)']\n",
    "\n",
    "df_tertiary = df_tertiary[~((df_tertiary['school_name'] == 'University of the Arts Singapore') & \n",
    "                             (~df_tertiary['google_school_name'].str.contains('University of the Arts Singapore', na=False)))]\n",
    "\n",
    "df_tertiary = df_tertiary[~((df_tertiary['school_name'] == 'SDH Institute') & \n",
    "                             (~df_tertiary['google_school_name'].str.contains('SDH Institute', na=False)))]\n",
    "\n",
    "df_tertiary.drop(columns={'google_school_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preschool_loc = df_preschool_loc.rename(columns={'centre_address': 'address'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_col_order = ['school_name', 'category', 'address', 'longitude', 'latitude']\n",
    "\n",
    "df_preschool_loc = df_preschool_loc[desired_col_order]\n",
    "df_moe_loc = df_moe_loc[desired_col_order]\n",
    "df_tertiary = df_tertiary[desired_col_order]\n",
    "\n",
    "df_combined = pd.concat([df_preschool_loc, df_moe_loc, df_tertiary], ignore_index=True)\n",
    "df_combined = df_combined.map(lambda x: x.strip().upper() if isinstance(x, str) else x)\n",
    "df_combined = df_combined.sort_values(by=['category', 'school_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows dropped: 3\n"
     ]
    }
   ],
   "source": [
    "#-- Drop rows with NA (ie. rows where address information cannot be retrieved)\n",
    "\n",
    "# Get the initial number of rows\n",
    "initial_rows = df_combined.shape[0]\n",
    "# Drop rows with NaN values\n",
    "df_combined = df_combined.dropna()\n",
    "# Get the final number of rows\n",
    "final_rows = df_combined.shape[0]\n",
    "# Print the number of rows dropped\n",
    "print(f\"Number of rows dropped: {initial_rows - final_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_csv('check schools.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
