{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- OneMap API Set-Up\n",
    "ONEMAP_BASE_URL = \"https://www.onemap.gov.sg/api/common/elastic/search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- Google API Set-Up\n",
    "GOOGLE_API_KEY = \"AIzaSyDpu7X3vaLLr2GhCX6BcNWhfUtcJwU8F-A\"\n",
    "TEXT_SEARCH_URL = \"https://maps.googleapis.com/maps/api/place/textsearch/json\"\n",
    "GEOCODE_URL = \"https://maps.googleapis.com/maps/api/geocode/json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get latitude and longitude using OneMap API for postal code\n",
    "def get_lat_lon_onemap(postal_code):\n",
    "\n",
    "    # Parameters for the API call (including your API Key)\n",
    "    params = {\n",
    "        'searchVal': postal_code,\n",
    "        'returnGeom': 'Y',\n",
    "        'getAddrDetails': 'Y'\n",
    "    }\n",
    "    \n",
    "    # Make the API request\n",
    "    response = requests.get(ONEMAP_BASE_URL, params=params)\n",
    "    \n",
    "    # Parse the response JSON\n",
    "    data = response.json()\n",
    "    \n",
    "    # Check if the response contains results\n",
    "    if data['found'] > 0:\n",
    "        # Extract latitude and longitude from the response\n",
    "        latitude = data['results'][0]['LATITUDE']\n",
    "        longitude = data['results'][0]['LONGITUDE']\n",
    "        return latitude, longitude\n",
    "    else:\n",
    "        # Return None if no results are found\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-School Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preschool_raw = pd.read_csv('preschool_loc_details_raw.csv', na_values=['na', 'NA', 'N/A', 'NULL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tp_code                         1848\n",
       "centre_code                       84\n",
       "centre_name                       48\n",
       "organisation_code                  0\n",
       "organisation_description           0\n",
       "service_model                     38\n",
       "centre_contact_no                  0\n",
       "centre_email_address              49\n",
       "centre_address                     0\n",
       "postal_code                        0\n",
       "centre_website                   475\n",
       "infant_vacancy_current_month       0\n",
       "infant_vacancy_next_month          0\n",
       "infant_vacancy_third_month         0\n",
       "infant_vacancy_fourth_month        0\n",
       "infant_vacancy_fifth_month         0\n",
       "infant_vacancy_sixth_month         0\n",
       "infant_vacancy_seventh_month       0\n",
       "pg_vacancy_current_month           0\n",
       "pg_vacancy_next_month              0\n",
       "pg_vacancy_third_month             0\n",
       "pg_vacancy_fourth_month            0\n",
       "pg_vacancy_fifth_month             0\n",
       "pg_vacancy_sixth_month             0\n",
       "pg_vacancy_seventh_month           0\n",
       "n1_vacancy_current_month           0\n",
       "n1_vacancy_next_month              0\n",
       "n1_vacancy_third_month             0\n",
       "n1_vacancy_fourth_month            0\n",
       "n1_vacancy_fifth_month             0\n",
       "n1_vacancy_sixth_month             0\n",
       "n1_vacancy_seventh_month           0\n",
       "n2_vacancy_current_month           0\n",
       "n2_vacancy_next_month              0\n",
       "n2_vacancy_third_month             0\n",
       "n2_vacancy_fourth_month            0\n",
       "n2_vacancy_fifth_month             0\n",
       "n2_vacancy_sixth_month             0\n",
       "n2_vacancy_seventh_month           0\n",
       "k1_vacancy_current_month           0\n",
       "k1_vacancy_next_month              0\n",
       "k1_vacancy_third_month             0\n",
       "k1_vacancy_fourth_month            0\n",
       "k1_vacancy_fifth_month             0\n",
       "k1_vacancy_sixth_month             0\n",
       "k1_vacancy_seventh_month           0\n",
       "k2_vacancy_current_month           0\n",
       "k2_vacancy_next_month              0\n",
       "k2_vacancy_third_month             0\n",
       "k2_vacancy_fourth_month            0\n",
       "k2_vacancy_fifth_month             0\n",
       "k2_vacancy_sixth_month             0\n",
       "k2_vacancy_seventh_month           0\n",
       "food_offered                     105\n",
       "second_languages_offered          63\n",
       "spark_certified                    0\n",
       "weekday_full_day                  58\n",
       "saturday                        1227\n",
       "scheme_type                      953\n",
       "extended_operating_hours           0\n",
       "provision_of_transport             0\n",
       "government_subsidy                 0\n",
       "gst_regisration                    0\n",
       "last_updated                       0\n",
       "remarks                         1979\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preschool_raw.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where 'centre_name' is null\n",
    "df_preschool_raw = df_preschool_raw[df_preschool_raw['centre_name'].notnull()]\n",
    "\n",
    "# Remove duplicates based on both 'centre_name' and 'postal_code'\n",
    "df_preschool_raw = df_preschool_raw.drop_duplicates(subset=['centre_name', 'postal_code'], keep='first')\n",
    "\n",
    "# Obtain relevant columns\n",
    "df_preschool_loc = df_preschool_raw[['centre_name', 'centre_address', 'postal_code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_11240\\3388511865.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_preschool_loc.loc[:, 'latitude'], df_preschool_loc.loc[:, 'longitude'] = zip(*df_preschool_loc['postal_code'].apply(get_lat_lon_onemap))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_11240\\3388511865.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_preschool_loc.loc[:, 'latitude'], df_preschool_loc.loc[:, 'longitude'] = zip(*df_preschool_loc['postal_code'].apply(get_lat_lon_onemap))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_11240\\3388511865.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_preschool_loc.loc[:, 'category'] = 'Preschool'\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_11240\\3388511865.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_preschool_loc.rename(columns={'centre_name': 'school_name'}, inplace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_11240\\3388511865.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_preschool_loc.drop(columns={'postal_code'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to get lat and lon for each preschool based on postal code\n",
    "# df_preschool_loc['latitude'], df_preschool_loc['longitude'] = zip(*df_preschool_loc['postal_code'].apply(get_lat_lon_onemap))\n",
    "# df_preschool_loc['category'] = 'Preschool'\n",
    "df_preschool_loc.loc[:, 'latitude'], df_preschool_loc.loc[:, 'longitude'] = zip(*df_preschool_loc['postal_code'].apply(get_lat_lon_onemap))\n",
    "df_preschool_loc.loc[:, 'category'] = 'Preschool'\n",
    "df_preschool_loc.rename(columns={'centre_name': 'school_name'}, inplace=True)\n",
    "df_preschool_loc.drop(columns={'postal_code'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOE Schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_11240\\78425934.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_moe_loc['latitude'], df_moe_loc['longitude'] = zip(*df_moe_loc['postal_code'].apply(get_lat_lon_onemap))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_11240\\78425934.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_moe_loc['latitude'], df_moe_loc['longitude'] = zip(*df_moe_loc['postal_code'].apply(get_lat_lon_onemap))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_11240\\78425934.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_moe_loc.rename(columns={'mainlevel_code': 'category'}, inplace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_11240\\78425934.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_moe_loc.drop(columns=['postal_code'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_moe_raw = pd.read_csv('moe_schools_raw.csv', na_values=['na', 'NA', 'N/A', 'NULL'])\n",
    "df_moe_raw = df_moe_raw.drop_duplicates(subset=['school_name', 'postal_code'], keep='first')\n",
    "df_moe_loc = df_moe_raw[['school_name', 'address', 'postal_code', 'mainlevel_code']]\n",
    "df_moe_loc.loc[df_moe_loc['mainlevel_code'] == 'MIXED LEVELS', 'mainlevel_code'] = 'IP/IB PROGRAMME'\n",
    "\n",
    "\n",
    "df_moe_loc['latitude'], df_moe_loc['longitude'] = zip(*df_moe_loc['postal_code'].apply(get_lat_lon_onemap))\n",
    "df_moe_loc.rename(columns={'mainlevel_code': 'category'}, inplace=True)\n",
    "df_moe_loc.drop(columns=['postal_code'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tertiary Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- Wiki URLs\n",
    "# School names are obtained from multiple source that give the most complete list of each category.\n",
    "UNI_WIKI_URL = \"https://en.wikipedia.org/wiki/List_of_universities_in_Singapore\"\n",
    "POLY_WIKI_URL = \"https://en.wikipedia.org/wiki/Education_in_Singapore\"\n",
    "ITE_WIKI_URL = \"https://en.wikipedia.org/wiki/Institute_of_Technical_Education#Colleges\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain school names, category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_university_names():\n",
    "    # Fetch the page content\n",
    "    response = requests.get(UNI_WIKI_URL)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Find the \"Universities in Singapore\" section by its ID\n",
    "    section_div = soup.find(\"div\", id=\"Universities_in_Singapore145\")\n",
    "\n",
    "    # List to store university data\n",
    "    university_list = []\n",
    "\n",
    "    if section_div:\n",
    "        # Locate \"Education in Singapore\" section to stop before it\n",
    "        stop_section = soup.find(\"div\", id=\"Education_in_Singapore254\")\n",
    "\n",
    "        # Find all categories (th elements)\n",
    "        categories = section_div.find_all_next(\"th\", scope=\"row\", class_=\"navbox-group\")\n",
    "\n",
    "        for category in categories:\n",
    "            # Stop if we reach \"Education in Singapore\"\n",
    "            if stop_section and category.find_previous(\"div\") == stop_section:\n",
    "                break\n",
    "\n",
    "            # Find the corresponding <td> which contains university names\n",
    "            next_td = category.find_next_sibling(\"td\")\n",
    "            if next_td:\n",
    "                for link in next_td.find_all(\"a\"):\n",
    "                    university_name = link.get_text(strip=True)\n",
    "                    university_list.append({\"school_name\": university_name, \"category\": \"University\"})\n",
    "    return pd.DataFrame(university_list)\n",
    "\n",
    "df_universities = get_university_names()\n",
    "df_universities = df_universities[df_universities['school_name'] != 'Singapore College of Islamic Studies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polytechnics():\n",
    "    response = requests.get(POLY_WIKI_URL)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Find the \"Polytechnics\" section\n",
    "    polytechnic_section = soup.find(\"h2\", {\"id\": \"Polytechnics\"})\n",
    "    polytechnic_list = []\n",
    "\n",
    "    if polytechnic_section:\n",
    "        # Locate the nearest paragraph (<p>) containing polytechnic names\n",
    "        para = polytechnic_section.find_next(\"p\")\n",
    "\n",
    "        # Extract all links within that paragraph\n",
    "        for link in para.find_all(\"a\"):\n",
    "            polytechnic_name = link.get_text(strip=True)\n",
    "            polytechnic_list.append({\"school_name\": polytechnic_name, \"category\": \"Polytechnic\"})\n",
    "    \n",
    "    return pd.DataFrame(polytechnic_list)\n",
    "\n",
    "df_polytechnics = get_polytechnics()\n",
    "df_polytechnics = df_polytechnics[df_polytechnics['school_name'] != '[71]'] # data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ite_names():\n",
    "    response = requests.get(ITE_WIKI_URL)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Find the \"Colleges\" section under an <h2> tag\n",
    "    ite_colleges_header = soup.find(\"h2\", {\"id\": \"Colleges\"})\n",
    "    ite_colleges_list = []\n",
    "\n",
    "    if ite_colleges_header:\n",
    "        # Locate the first <ul> after the <h2> heading (which contains the list)\n",
    "        ul = ite_colleges_header.find_next(\"ul\")\n",
    "\n",
    "        if ul:\n",
    "            for link in ul.find_all(\"a\"):\n",
    "                college_name = link.get_text(strip=True)\n",
    "                ite_colleges_list.append({\"school_name\": college_name, \"category\": \"ITE College\"})\n",
    "\n",
    "    return pd.DataFrame(ite_colleges_list)\n",
    "\n",
    "df_ite_colleges = get_ite_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tertiary = pd.concat([df_universities, df_polytechnics, df_ite_colleges], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain location information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_ter_school_details_google(school_name):\n",
    "    query = school_name + \" Singapore\"  # Construct query for text search\n",
    "    \n",
    "    params = {\n",
    "        \"query\": query,  # The text search query\n",
    "        \"key\": GOOGLE_API_KEY\n",
    "    }\n",
    "    \n",
    "    response = requests.get(TEXT_SEARCH_URL, params=params)\n",
    "    data = response.json()\n",
    "    \n",
    "    results_list = []\n",
    "    \n",
    "    if data[\"status\"] == \"OK\":\n",
    "        for result in data[\"results\"]:  # Loop through all the results\n",
    "            name = result[\"name\"]\n",
    "            address = result[\"formatted_address\"]\n",
    "            lat = result[\"geometry\"][\"location\"][\"lat\"]\n",
    "            lng = result[\"geometry\"][\"location\"][\"lng\"]\n",
    "            \n",
    "            results_list.append({\n",
    "                \"school_name\": school_name,\n",
    "                \"google_school_name\": name,  # Store the official name returned\n",
    "                \"address\": address,\n",
    "                \"longitude\": lng,\n",
    "                \"latitude\": lat\n",
    "            })\n",
    "    \n",
    "    # If no valid results, return a placeholder\n",
    "    if not results_list:\n",
    "        results_list.append({\n",
    "            \"school_name\": school_name,\n",
    "            \"google_school_name\": None,\n",
    "            \"address\": None,\n",
    "            \"longitude\": None,\n",
    "            \"latitude\": None\n",
    "        })\n",
    "    \n",
    "    return results_list  # Returns a list of all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_ter_school_details_onemap(school_name):\n",
    "#     params = {\n",
    "#         \"searchVal\": school_name,  # The school name to search\n",
    "#         \"returnGeom\": \"Y\",  # Return geometry (latitude/longitude)\n",
    "#         \"getAddrDetails\": \"Y\",  # Get detailed address information\n",
    "#     }\n",
    "    \n",
    "#     response = requests.get(ONEMAP_BASE_URL, params=params)\n",
    "#     data = response.json()\n",
    "    \n",
    "#     results_list = []\n",
    "    \n",
    "#     if data[\"found\"] > 0:\n",
    "#         for result in data[\"results\"]:  # Loop through all the results\n",
    "#             address = result[\"ADDRESS\"]\n",
    "#             lat = result[\"LATITUDE\"]\n",
    "#             lng = result[\"LONGITUDE\"]\n",
    "            \n",
    "#             results_list.append({\n",
    "#                 \"school_name\": school_name,\n",
    "#                 \"onemap_school_name\": address,  # Store the address returned by OneMap\n",
    "#                 \"address\": address,\n",
    "#                 \"longitude\": lng,\n",
    "#                 \"latitude\": lat\n",
    "#             })\n",
    "    \n",
    "#     # If no valid results, return a placeholder\n",
    "#     if not results_list:\n",
    "#         results_list.append({\n",
    "#             \"school_name\": school_name,\n",
    "#             \"onemap_school_name\": None,\n",
    "#             \"address\": None,\n",
    "#             \"longitude\": None,\n",
    "#             \"latitude\": None\n",
    "#         })\n",
    "    \n",
    "#     return results_list  # Returns a list of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ter_loc_details = []\n",
    "for _, row in df_tertiary.iterrows():\n",
    "    school_name = row['school_name']\n",
    "    category = row['category']\n",
    "    ter_loc_details.extend(get_ter_school_details_google(school_name))  # Extend with multiple results\n",
    "\n",
    "df_ter_loc_details = pd.DataFrame(ter_loc_details)\n",
    "\n",
    "# Merge back \n",
    "df_tertiary = df_tertiary.merge(df_ter_loc_details, on=['school_name'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual cleaning\n",
    "df_tertiary = df_tertiary[df_tertiary['google_school_name'] != 'Singapore Institute of Manufacturing Technology (SIMTech)']\n",
    "\n",
    "df_tertiary = df_tertiary[~((df_tertiary['school_name'] == 'University of the Arts Singapore') & \n",
    "                             (~df_tertiary['google_school_name'].str.contains('University of the Arts Singapore', na=False)))]\n",
    "\n",
    "df_tertiary = df_tertiary[~((df_tertiary['school_name'] == 'SDH Institute') & \n",
    "                             (~df_tertiary['google_school_name'].str.contains('SDH Institute', na=False)))]\n",
    "\n",
    "df_tertiary.drop(columns={'google_school_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preschool_loc = df_preschool_loc.rename(columns={'centre_address': 'address'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_col_order = ['school_name', 'category', 'address', 'longitude', 'latitude']\n",
    "\n",
    "df_preschool_loc = df_preschool_loc[desired_col_order]\n",
    "df_moe_loc = df_moe_loc[desired_col_order]\n",
    "df_tertiary = df_tertiary[desired_col_order]\n",
    "\n",
    "df_combined = pd.concat([df_preschool_loc, df_moe_loc, df_tertiary], ignore_index=True)\n",
    "df_combined = df_combined.map(lambda x: x.strip().upper() if isinstance(x, str) else x)\n",
    "df_combined = df_combined.sort_values(by=['category', 'school_name'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
